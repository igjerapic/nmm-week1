--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD
with errorcode 1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
srun: error: node111: task 0: Exited with exit code 1
srun: Terminating StepId=16678939.0

###############################################################################
H치br칩k Cluster
Job 16678939 for user s4437586
Finished at: Thu Apr 17 12:22:25 CEST 2025

Job details:
============

Job ID                         : 16678939
Name                           : test
User                           : s4437586
Partition                      : regularshort
Nodes                          : node111
Number of Nodes                : 1
Cores                          : 1
Number of Tasks                : 1
State                          : FAILED  
Submit                         : 2025-04-17T12:22:11
Start                          : 2025-04-17T12:22:12
End                            : 2025-04-17T12:22:21
Reserved walltime              : 00:20:00
Used walltime                  : 00:00:09
Used CPU time                  : 00:00:04 (Efficiency: 42.04%)
% User (Computation)           : 77.70%
% System (I/O)                 : 22.28%
Total memory reserved          : 2000M
Maximum memory used            : 0.00 

Acknowledgements:
=================

Please see this page for information about acknowledging H치br칩k in your publications:

https://wiki.hpc.rug.nl/habrok/introduction/scientific_output

################################################################################
